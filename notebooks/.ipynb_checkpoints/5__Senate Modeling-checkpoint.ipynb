{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Senate Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries, Set Options and Styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/Alexz/CodeMaster/capstone/capstone_repo/data/sens_final.csv')\n",
    "df.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>office</th>\n",
       "      <th>loc_date_id</th>\n",
       "      <th>state</th>\n",
       "      <th>abbrev</th>\n",
       "      <th>year</th>\n",
       "      <th>GOP_win</th>\n",
       "      <th>winner</th>\n",
       "      <th>rival</th>\n",
       "      <th>pred_GOP</th>\n",
       "      <th>pred_DEM</th>\n",
       "      <th>unopposed</th>\n",
       "      <th>inc_GOP_running</th>\n",
       "      <th>inc_DEM_running</th>\n",
       "      <th>prez_GOP</th>\n",
       "      <th>approval_effects_GOP</th>\n",
       "      <th>approval_effects_DEM</th>\n",
       "      <th>nat_UR_effects_GOP</th>\n",
       "      <th>nat_UR_effects_DEM</th>\n",
       "      <th>state_UR_effects_GOP</th>\n",
       "      <th>state_UR_effects_DEM</th>\n",
       "      <th>total_male</th>\n",
       "      <th>total_female</th>\n",
       "      <th>age_under18</th>\n",
       "      <th>age_18to29</th>\n",
       "      <th>age_30to59</th>\n",
       "      <th>age_60over</th>\n",
       "      <th>race_white_nh</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_natamer</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>percent_male</th>\n",
       "      <th>percent_female</th>\n",
       "      <th>percent_under18</th>\n",
       "      <th>percent_age_18to29</th>\n",
       "      <th>percent_age_30to59</th>\n",
       "      <th>percent_age_60over</th>\n",
       "      <th>percent_race_white</th>\n",
       "      <th>percent_race_black</th>\n",
       "      <th>percent_race_natamer</th>\n",
       "      <th>percent_race_asian</th>\n",
       "      <th>percent_race_hispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK_sen_1978</td>\n",
       "      <td>AK_sen</td>\n",
       "      <td>AK_1978</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "      <td>1978</td>\n",
       "      <td>1</td>\n",
       "      <td>Ted Stevens</td>\n",
       "      <td>Donald W  Hobbs</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>203084</td>\n",
       "      <td>178473</td>\n",
       "      <td>128568</td>\n",
       "      <td>101180</td>\n",
       "      <td>133656</td>\n",
       "      <td>18154</td>\n",
       "      <td>288403</td>\n",
       "      <td>12781</td>\n",
       "      <td>54741</td>\n",
       "      <td>14337</td>\n",
       "      <td>8525</td>\n",
       "      <td>0.532251</td>\n",
       "      <td>0.467749</td>\n",
       "      <td>0.336956</td>\n",
       "      <td>0.265177</td>\n",
       "      <td>0.350291</td>\n",
       "      <td>0.047579</td>\n",
       "      <td>0.755858</td>\n",
       "      <td>0.033497</td>\n",
       "      <td>0.143467</td>\n",
       "      <td>0.037575</td>\n",
       "      <td>0.022343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL_sen_1978</td>\n",
       "      <td>AL_sen</td>\n",
       "      <td>AL_1978</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>1978</td>\n",
       "      <td>0</td>\n",
       "      <td>Howell Heflin</td>\n",
       "      <td>Jerome B  Couch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1829615</td>\n",
       "      <td>1974328</td>\n",
       "      <td>1176502</td>\n",
       "      <td>788346</td>\n",
       "      <td>1256746</td>\n",
       "      <td>582349</td>\n",
       "      <td>2770988</td>\n",
       "      <td>977720</td>\n",
       "      <td>7932</td>\n",
       "      <td>9413</td>\n",
       "      <td>34409</td>\n",
       "      <td>0.480979</td>\n",
       "      <td>0.519021</td>\n",
       "      <td>0.309285</td>\n",
       "      <td>0.207244</td>\n",
       "      <td>0.330380</td>\n",
       "      <td>0.153091</td>\n",
       "      <td>0.728452</td>\n",
       "      <td>0.257028</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.009046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL_sen2_1978</td>\n",
       "      <td>AL_sen</td>\n",
       "      <td>AL_1978</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>1978</td>\n",
       "      <td>0</td>\n",
       "      <td>Donald W  Stewart</td>\n",
       "      <td>James D  Martin</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1829615</td>\n",
       "      <td>1974328</td>\n",
       "      <td>1176502</td>\n",
       "      <td>788346</td>\n",
       "      <td>1256746</td>\n",
       "      <td>582349</td>\n",
       "      <td>2770988</td>\n",
       "      <td>977720</td>\n",
       "      <td>7932</td>\n",
       "      <td>9413</td>\n",
       "      <td>34409</td>\n",
       "      <td>0.480979</td>\n",
       "      <td>0.519021</td>\n",
       "      <td>0.309285</td>\n",
       "      <td>0.207244</td>\n",
       "      <td>0.330380</td>\n",
       "      <td>0.153091</td>\n",
       "      <td>0.728452</td>\n",
       "      <td>0.257028</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.009046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR_sen_1978</td>\n",
       "      <td>AR_sen</td>\n",
       "      <td>AR_1978</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "      <td>1978</td>\n",
       "      <td>0</td>\n",
       "      <td>David Pryor</td>\n",
       "      <td>Tom Kelly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1070212</td>\n",
       "      <td>1143595</td>\n",
       "      <td>668101</td>\n",
       "      <td>427351</td>\n",
       "      <td>713077</td>\n",
       "      <td>405278</td>\n",
       "      <td>1805936</td>\n",
       "      <td>368909</td>\n",
       "      <td>10608</td>\n",
       "      <td>6370</td>\n",
       "      <td>19195</td>\n",
       "      <td>0.483426</td>\n",
       "      <td>0.516574</td>\n",
       "      <td>0.301788</td>\n",
       "      <td>0.193039</td>\n",
       "      <td>0.322104</td>\n",
       "      <td>0.183068</td>\n",
       "      <td>0.815760</td>\n",
       "      <td>0.166640</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.008671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CO_sen_1978</td>\n",
       "      <td>CO_sen</td>\n",
       "      <td>CO_1978</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>CO</td>\n",
       "      <td>1978</td>\n",
       "      <td>1</td>\n",
       "      <td>William L  Armstrong</td>\n",
       "      <td>Floyd K  Haskell</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1365310</td>\n",
       "      <td>1388113</td>\n",
       "      <td>801853</td>\n",
       "      <td>666524</td>\n",
       "      <td>951729</td>\n",
       "      <td>333317</td>\n",
       "      <td>2178611</td>\n",
       "      <td>94638</td>\n",
       "      <td>18579</td>\n",
       "      <td>31338</td>\n",
       "      <td>316875</td>\n",
       "      <td>0.495859</td>\n",
       "      <td>0.504141</td>\n",
       "      <td>0.291220</td>\n",
       "      <td>0.242071</td>\n",
       "      <td>0.345653</td>\n",
       "      <td>0.121056</td>\n",
       "      <td>0.791237</td>\n",
       "      <td>0.034371</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.115084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        race_id  office loc_date_id     state abbrev  year  GOP_win  \\\n",
       "0   AK_sen_1978  AK_sen     AK_1978    Alaska     AK  1978        1   \n",
       "1   AL_sen_1978  AL_sen     AL_1978   Alabama     AL  1978        0   \n",
       "2  AL_sen2_1978  AL_sen     AL_1978   Alabama     AL  1978        0   \n",
       "3   AR_sen_1978  AR_sen     AR_1978  Arkansas     AR  1978        0   \n",
       "4   CO_sen_1978  CO_sen     CO_1978  Colorado     CO  1978        1   \n",
       "\n",
       "                 winner             rival  pred_GOP  pred_DEM  unopposed  \\\n",
       "0           Ted Stevens   Donald W  Hobbs         1         0          0   \n",
       "1         Howell Heflin   Jerome B  Couch         0         1          0   \n",
       "2     Donald W  Stewart   James D  Martin         0         1          0   \n",
       "3           David Pryor         Tom Kelly         0         1          0   \n",
       "4  William L  Armstrong  Floyd K  Haskell         0         1          0   \n",
       "\n",
       "   inc_GOP_running  inc_DEM_running  prez_GOP  approval_effects_GOP  \\\n",
       "0                1                0       0.0                   0.0   \n",
       "1                0                0       0.0                   0.0   \n",
       "2                0                0       0.0                   0.0   \n",
       "3                0                0       0.0                   0.0   \n",
       "4                0                1       0.0                   0.0   \n",
       "\n",
       "   approval_effects_DEM  nat_UR_effects_GOP  nat_UR_effects_DEM  \\\n",
       "0                  13.0                 0.0                 5.8   \n",
       "1                  13.0                 0.0                 5.8   \n",
       "2                  13.0                 0.0                 5.8   \n",
       "3                  13.0                 0.0                 5.8   \n",
       "4                  13.0                 0.0                 5.8   \n",
       "\n",
       "   state_UR_effects_GOP  state_UR_effects_DEM  total_male  total_female  \\\n",
       "0                   0.0                  10.2      203084        178473   \n",
       "1                   0.0                   6.5     1829615       1974328   \n",
       "2                   0.0                   6.5     1829615       1974328   \n",
       "3                   0.0                   6.4     1070212       1143595   \n",
       "4                   0.0                   5.1     1365310       1388113   \n",
       "\n",
       "   age_under18  age_18to29  age_30to59  age_60over  race_white_nh  race_black  \\\n",
       "0       128568      101180      133656       18154         288403       12781   \n",
       "1      1176502      788346     1256746      582349        2770988      977720   \n",
       "2      1176502      788346     1256746      582349        2770988      977720   \n",
       "3       668101      427351      713077      405278        1805936      368909   \n",
       "4       801853      666524      951729      333317        2178611       94638   \n",
       "\n",
       "   race_natamer  race_asian  race_hispanic  percent_male  percent_female  \\\n",
       "0         54741       14337           8525      0.532251        0.467749   \n",
       "1          7932        9413          34409      0.480979        0.519021   \n",
       "2          7932        9413          34409      0.480979        0.519021   \n",
       "3         10608        6370          19195      0.483426        0.516574   \n",
       "4         18579       31338         316875      0.495859        0.504141   \n",
       "\n",
       "   percent_under18  percent_age_18to29  percent_age_30to59  \\\n",
       "0         0.336956            0.265177            0.350291   \n",
       "1         0.309285            0.207244            0.330380   \n",
       "2         0.309285            0.207244            0.330380   \n",
       "3         0.301788            0.193039            0.322104   \n",
       "4         0.291220            0.242071            0.345653   \n",
       "\n",
       "   percent_age_60over  percent_race_white  percent_race_black  \\\n",
       "0            0.047579            0.755858            0.033497   \n",
       "1            0.153091            0.728452            0.257028   \n",
       "2            0.153091            0.728452            0.257028   \n",
       "3            0.183068            0.815760            0.166640   \n",
       "4            0.121056            0.791237            0.034371   \n",
       "\n",
       "   percent_race_natamer  percent_race_asian  percent_race_hispanic  \n",
       "0              0.143467            0.037575               0.022343  \n",
       "1              0.002085            0.002475               0.009046  \n",
       "2              0.002085            0.002475               0.009046  \n",
       "3              0.004792            0.002877               0.008671  \n",
       "4              0.006748            0.011381               0.115084  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_codes = df.abbrev.unique()\n",
    "state_names = df.state.unique()\n",
    "years = list(range(1976, 2018))\n",
    "\n",
    "id_cols = ['office', 'loc_date_id', 'race_id', 'state', 'abbrev', 'year', 'winner', 'rival']\n",
    "\n",
    "percent_columns = ['percent_male', 'percent_under18', 'percent_age_18to29', \n",
    "                   'percent_age_30to59', 'percent_age_60over', 'percent_race_white', 'percent_race_black',\n",
    "                   'percent_race_natamer', 'percent_race_asian', 'percent_race_hispanic']\n",
    "amnt_columns = ['total_male', 'total_female', 'age_under18', 'age_18to29', 'age_30to59',\n",
    "       'age_60over', 'race_white_nh', 'race_black', 'race_natamer', 'race_asian', 'race_hispanic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(598, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_GOP</th>\n",
       "      <th>pred_DEM</th>\n",
       "      <th>unopposed</th>\n",
       "      <th>inc_GOP_running</th>\n",
       "      <th>inc_DEM_running</th>\n",
       "      <th>prez_GOP</th>\n",
       "      <th>approval_effects_GOP</th>\n",
       "      <th>approval_effects_DEM</th>\n",
       "      <th>nat_UR_effects_GOP</th>\n",
       "      <th>nat_UR_effects_DEM</th>\n",
       "      <th>state_UR_effects_GOP</th>\n",
       "      <th>state_UR_effects_DEM</th>\n",
       "      <th>percent_female</th>\n",
       "      <th>percent_age_18to29</th>\n",
       "      <th>percent_age_30to59</th>\n",
       "      <th>percent_age_60over</th>\n",
       "      <th>percent_race_white</th>\n",
       "      <th>percent_race_black</th>\n",
       "      <th>percent_race_asian</th>\n",
       "      <th>percent_race_hispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.467749</td>\n",
       "      <td>0.265177</td>\n",
       "      <td>0.350291</td>\n",
       "      <td>0.047579</td>\n",
       "      <td>0.755858</td>\n",
       "      <td>0.033497</td>\n",
       "      <td>0.037575</td>\n",
       "      <td>0.022343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.519021</td>\n",
       "      <td>0.207244</td>\n",
       "      <td>0.330380</td>\n",
       "      <td>0.153091</td>\n",
       "      <td>0.728452</td>\n",
       "      <td>0.257028</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.009046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.519021</td>\n",
       "      <td>0.207244</td>\n",
       "      <td>0.330380</td>\n",
       "      <td>0.153091</td>\n",
       "      <td>0.728452</td>\n",
       "      <td>0.257028</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.009046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.516574</td>\n",
       "      <td>0.193039</td>\n",
       "      <td>0.322104</td>\n",
       "      <td>0.183068</td>\n",
       "      <td>0.815760</td>\n",
       "      <td>0.166640</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.008671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.504141</td>\n",
       "      <td>0.242071</td>\n",
       "      <td>0.345653</td>\n",
       "      <td>0.121056</td>\n",
       "      <td>0.791237</td>\n",
       "      <td>0.034371</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.115084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_GOP  pred_DEM  unopposed  inc_GOP_running  inc_DEM_running  prez_GOP  \\\n",
       "0         1         0          0                1                0       0.0   \n",
       "1         0         1          0                0                0       0.0   \n",
       "2         0         1          0                0                0       0.0   \n",
       "3         0         1          0                0                0       0.0   \n",
       "4         0         1          0                0                1       0.0   \n",
       "\n",
       "   approval_effects_GOP  approval_effects_DEM  nat_UR_effects_GOP  \\\n",
       "0                   0.0                  13.0                 0.0   \n",
       "1                   0.0                  13.0                 0.0   \n",
       "2                   0.0                  13.0                 0.0   \n",
       "3                   0.0                  13.0                 0.0   \n",
       "4                   0.0                  13.0                 0.0   \n",
       "\n",
       "   nat_UR_effects_DEM  state_UR_effects_GOP  state_UR_effects_DEM  \\\n",
       "0                 5.8                   0.0                  10.2   \n",
       "1                 5.8                   0.0                   6.5   \n",
       "2                 5.8                   0.0                   6.5   \n",
       "3                 5.8                   0.0                   6.4   \n",
       "4                 5.8                   0.0                   5.1   \n",
       "\n",
       "   percent_female  percent_age_18to29  percent_age_30to59  percent_age_60over  \\\n",
       "0        0.467749            0.265177            0.350291            0.047579   \n",
       "1        0.519021            0.207244            0.330380            0.153091   \n",
       "2        0.519021            0.207244            0.330380            0.153091   \n",
       "3        0.516574            0.193039            0.322104            0.183068   \n",
       "4        0.504141            0.242071            0.345653            0.121056   \n",
       "\n",
       "   percent_race_white  percent_race_black  percent_race_asian  \\\n",
       "0            0.755858            0.033497            0.037575   \n",
       "1            0.728452            0.257028            0.002475   \n",
       "2            0.728452            0.257028            0.002475   \n",
       "3            0.815760            0.166640            0.002877   \n",
       "4            0.791237            0.034371            0.011381   \n",
       "\n",
       "   percent_race_hispanic  \n",
       "0               0.022343  \n",
       "1               0.009046  \n",
       "2               0.009046  \n",
       "3               0.008671  \n",
       "4               0.115084  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#basic setup\n",
    "y = df['GOP_win']\n",
    "X = df.drop('GOP_win', axis=1)\n",
    "\n",
    "# drop non-analysis vars\n",
    "X.drop(id_cols, inplace=True, axis=1)\n",
    "\n",
    "\n",
    "# Option 1: drop amount vars from X\n",
    "X.drop(amnt_columns, axis=1, inplace=True)\n",
    "# drop out group from binary/collinear groups\n",
    "X.drop(['percent_male', 'percent_under18', 'percent_race_natamer'], inplace=True, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Option 2: drop percentage vars\n",
    "# X.drop(percent_columns, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(19)\n",
    "#train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)\n",
    "\n",
    "# scale data \n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train, y_train)\n",
    "X_train_sc = ss.transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)\n",
    "\n",
    "# initiate all models\n",
    "logreg_class = LogisticRegression()\n",
    "\n",
    "knn_class = KNeighborsClassifier()\n",
    "\n",
    "dt_class = DecisionTreeClassifier()\n",
    "\n",
    "bagged_class = BaggingClassifier()\n",
    "\n",
    "rf_class = RandomForestClassifier()\n",
    "\n",
    "adaboost_class = AdaBoostClassifier()\n",
    "\n",
    "support_vector_class = SVC()\n",
    "\n",
    "#list of models\n",
    "models = [logreg_class, knn_class,dt_class, rf_class, bagged_class, adaboost_class, support_vector_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this particular model, we want to use Accuracy as our metric to optimize each model.\n",
    "The model is a two-class classifcation problem where a classification of 1 indicates a win for the GOP candidate and a classification of 0 indicates a win for the Democratic candidate. Since this study is intended to be unbiased, we value a false negative and false positive the same: a wrong prediction. If we were working for one party or saw unquantifiable signs in favor of one party, we may want to minimize false positives or negatives to be more pessimistic or optimistic in one direction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Model: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Mean CV Scores: 0.8157598571170193\n",
      "Std CV Scores: 0.04287724529306988\n",
      "\n",
      "\n",
      " Model: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "Mean CV Scores: 0.7991133116295894\n",
      "Std CV Scores: 0.031543715080883404\n",
      "\n",
      "\n",
      " Model: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Mean CV Scores: 0.7381927111593416\n",
      "Std CV Scores: 0.04838418837067709\n",
      "\n",
      "\n",
      " Model: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Mean CV Scores: 0.8157603092783505\n",
      "Std CV Scores: 0.03970923359394369\n",
      "\n",
      "\n",
      " Model: BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False)\n",
      "Mean CV Scores: 0.7654519352504974\n",
      "Std CV Scores: 0.04139743190194221\n",
      "\n",
      "\n",
      " Model: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "Mean CV Scores: 0.7738940133839753\n",
      "Std CV Scores: 0.03986948085336309\n",
      "\n",
      "\n",
      " Model: SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Mean CV Scores: 0.8262427654187015\n",
      "Std CV Scores: 0.024304049381492727\n"
     ]
    }
   ],
   "source": [
    "#all cross val scores\n",
    "for model in models:\n",
    "    random.seed(19)\n",
    "    cv_scores = cross_val_score(model, X_train_sc,  y_train, cv=5)\n",
    "    print('\\n\\n Model:', model)\n",
    "    print('Mean CV Scores:', cv_scores.mean())\n",
    "    print('Std CV Scores:', cv_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'penalty': 'l2'}\n",
      "Train Accuracy:   0.8284518828451883\n",
      "Test Accuracy:   0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "param_grid = { 'C' : [.001, .01, .1, 1, 10, 100, 1000],\n",
    "               'penalty' : ['l1', 'l2']\n",
    "             }\n",
    "\n",
    "clf = GridSearchCV(logreg_class, param_grid, cv=3)\n",
    "clf.fit(X_train_sc, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "C_opt = clf.best_params_['C']\n",
    "penalty_opt = clf.best_params_['penalty']\n",
    "\n",
    "lr_opt = LogisticRegression(penalty=penalty_opt, C=C_opt)\n",
    "lr_opt.fit(X_train_sc, y_train)\n",
    "\n",
    "y_hat_train = lr_opt.predict(X_train_sc)\n",
    "y_hat_test = lr_opt.predict(X_test_sc)\n",
    "\n",
    "print(\"Train Accuracy:  \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test Accuracy:  \", accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:   0.8284518828451883\n",
      "Test Accuracy:   0.8583333333333333\n"
     ]
    }
   ],
   "source": [
    "lr_opt = LogisticRegression(penalty='l1', C=.2)\n",
    "lr_opt.fit(X_train_sc, y_train)\n",
    "\n",
    "y_hat_train = lr_opt.predict(X_train_sc)\n",
    "y_hat_test = lr_opt.predict(X_test_sc)\n",
    "\n",
    "print(\"Train Accuracy:  \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test Accuracy:  \", accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': 1, 'n_neighbors': 17}\n",
      "Train Accuracy:   0.99581589958159\n",
      "Test Accuracy:   0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors' : range(1, 25, 1),\n",
    "              'leaf_size' : range(1, 10, 1)\n",
    "             }\n",
    "\n",
    "knn_class = KNeighborsClassifier(weights='distance',\n",
    "                                 leaf_size = 1)\n",
    "clf = GridSearchCV(knn_class, param_grid, cv=3)\n",
    "clf.fit(X_train_sc, y_train)\n",
    "\n",
    "\n",
    "print(clf.best_params_)\n",
    "\n",
    "y_hat_train = clf.predict(X_train_sc)\n",
    "y_hat_test = clf.predict(X_test_sc)\n",
    "\n",
    "print(\"Train Accuracy:  \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test Accuracy:  \", accuracy_score(y_test, y_hat_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:   0.8200836820083682\n",
      "Test Accuracy:   0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "knn_opt = KNeighborsClassifier(algorithm='auto', leaf_size=3, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=17, p=2,\n",
    "           weights='uniform')\n",
    "\n",
    "knn_opt.fit(X_train_sc, y_train)\n",
    "\n",
    "y_hat_train = knn_opt.predict(X_train_sc)\n",
    "y_hat_test = knn_opt.predict(X_test_sc)\n",
    "\n",
    "print(\"Train Accuracy:  \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test Accuracy:  \", accuracy_score(y_test, y_hat_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt'}\n",
      "Train Accuracy:   0.8556485355648535\n",
      "Test Accuracy:   0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "random.seed(19)\n",
    "param_grid = {'criterion' : ['gini', 'entropy'],\n",
    "              'max_depth' : [5, 10, 15, 20, 50],\n",
    "              'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "             }\n",
    "clf = GridSearchCV(dt_class, param_grid, cv=3)\n",
    "clf.fit(X_train_sc, y_train)\n",
    "print(clf.best_params_)\n",
    "c = clf.best_params_['criterion']\n",
    "md = clf.best_params_['max_depth']\n",
    "mf = clf.best_params_['max_features']\n",
    "\n",
    "clf_opt = DecisionTreeClassifier(criterion=c, max_depth=md, max_features=mf)\n",
    "clf_opt.fit(X_train_sc, y_train)\n",
    "\n",
    "y_hat_train = clf_opt.predict(X_train_sc)\n",
    "y_hat_test = clf_opt.predict(X_test_sc)\n",
    "\n",
    "print(\"Train Accuracy:  \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test Accuracy:  \", accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:   0.8514644351464435\n",
      "Test Accuracy:   0.825\n",
      "\n",
      "Gap: 0.026464435146443588\n"
     ]
    }
   ],
   "source": [
    "dt_opt = DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features='sqrt', random_state=19)\n",
    "dt_opt.fit(X_train_sc, y_train)\n",
    "\n",
    "y_hat_train = dt_opt.predict(X_train_sc)\n",
    "y_hat_test = dt_opt.predict(X_test_sc)\n",
    "\n",
    "print(\"Train Accuracy:  \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test Accuracy:  \", accuracy_score(y_test, y_hat_test))\n",
    "print(\"\\nGap:\", (accuracy_score(y_train, y_hat_train) - accuracy_score(y_test, y_hat_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4: Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_samples': 0.6, 'n_estimators': 16}\n",
      "Train Accuracy:   0.9581589958158996\n",
      "Test Accuracy:   0.8083333333333333\n"
     ]
    }
   ],
   "source": [
    "random.seed(19)\n",
    "param_grid = {'n_estimators' : range(10, 25),\n",
    "              'max_samples' : [.6, .75, .8, 1]             \n",
    "             }\n",
    "clf = GridSearchCV(bagged_class, param_grid, cv=3)\n",
    "clf.fit(X_train_sc, y_train)\n",
    "print(clf.best_params_)\n",
    "n = clf.best_params_['n_estimators']\n",
    "ms = clf.best_params_['max_samples']\n",
    "\n",
    "bag_opt = BaggingClassifier(n_estimators=n, max_samples=ms)\n",
    "bag_opt.fit(X_train_sc, y_train)\n",
    "\n",
    "y_hat_train = bag_opt.predict(X_train_sc)\n",
    "y_hat_test = bag_opt.predict(X_test_sc)\n",
    "\n",
    "print(\"Train Accuracy:  \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test Accuracy:  \", accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 5: Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 40, 'n_estimators': 5}\n",
      "Train Accuracy:   0.9811715481171548\n",
      "Test Accuracy:   0.7916666666666666\n"
     ]
    }
   ],
   "source": [
    "random.seed(19)\n",
    "param_grid = {'n_estimators' : [5, 8, 10, 15],\n",
    "              'criterion' : ['gini', 'entropy'],\n",
    "              'max_depth' : [10, 25, 40],\n",
    "              }\n",
    "clf = GridSearchCV(rf_class, param_grid, cv=3)\n",
    "clf.fit(X_train_sc, y_train)\n",
    "print(clf.best_params_)\n",
    "n = clf.best_params_['n_estimators']\n",
    "c = clf.best_params_['criterion']\n",
    "md = clf.best_params_['max_depth']\n",
    "\n",
    "rf_opt = RandomForestClassifier(n_estimators=n, criterion=c, max_depth=md)\n",
    "rf_opt.fit(X_train_sc, y_train)\n",
    "\n",
    "y_hat_train = rf_opt.predict(X_train_sc)\n",
    "y_hat_test = rf_opt.predict(X_test_sc)\n",
    "\n",
    "print(\"Train Accuracy:  \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test Accuracy:  \", accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:   0.8682008368200836\n",
      "Test Accuracy:   0.8416666666666667\n"
     ]
    }
   ],
   "source": [
    "rf_opt = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=5, random_state=19)\n",
    "rf_opt.fit(X_train_sc, y_train)\n",
    "\n",
    "y_hat_train = rf_opt.predict(X_train_sc)\n",
    "y_hat_test = rf_opt.predict(X_test_sc)\n",
    "\n",
    "print(\"Train Accuracy:  \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test Accuracy:  \", accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 6: Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1, 'n_estimators': 84}\n",
      "Train Accuracy:   0.9225941422594143\n",
      "Test Accuracy:   0.8416666666666667\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators' : range(60, 100, 4),\n",
    "              'learning_rate': [.5, 1, 1.25, 1.5, 1.75]\n",
    "    \n",
    "}\n",
    "clf = GridSearchCV(adaboost_class, param_grid, cv=3)\n",
    "clf.fit(X_train_sc, y_train)\n",
    "print(clf.best_params_)\n",
    "n = clf.best_params_['n_estimators']\n",
    "lr = clf.best_params_['learning_rate']\n",
    "\n",
    "clf_opt = AdaBoostClassifier(n_estimators=n, learning_rate=lr, random_state=19)\n",
    "clf_opt.fit(X_train_sc, y_train)\n",
    "\n",
    "y_hat_train = clf_opt.predict(X_train_sc)\n",
    "y_hat_test = clf_opt.predict(X_test_sc)\n",
    "\n",
    "print(\"Train Accuracy:  \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test Accuracy:  \", accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:   0.8514644351464435\n",
      "Test Accuracy:   0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "boost_opt = AdaBoostClassifier(n_estimators = 20,\n",
    "                               learning_rate = 1,\n",
    "                               random_state = 19)\n",
    "\n",
    "boost_opt.fit(X_train_sc, y_train)\n",
    "\n",
    "y_hat_train = boost_opt.predict(X_train_sc)\n",
    "y_hat_test = boost_opt.predict(X_test_sc)\n",
    "\n",
    "print(\"Train Accuracy:  \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test Accuracy:  \", accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 7: SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "Train Accuracy:   0.8472803347280334\n",
      "Test Accuracy:   0.825\n"
     ]
    }
   ],
   "source": [
    "random.seed(19)\n",
    "param_grid = { 'C' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma' : [.001, .01, .1, 1, 10, 100],\n",
    "              'kernel' : ['poly']\n",
    "             }\n",
    "\n",
    "clf = GridSearchCV(support_vector_class, param_grid, cv=3)\n",
    "clf.fit(X_train_sc, y_train)\n",
    "print(clf.best_params_)\n",
    "# c = clf.best_params_['C']\n",
    "# g = clf.best_params_['gamma']\n",
    "k = clf.best_params_['kernel']\n",
    "\n",
    "svm_opt = SVC(kernel = k, probability=True)\n",
    "svm_opt.fit(X_train_sc, y_train)\n",
    "\n",
    "y_hat_train = svm_opt.predict(X_train_sc)\n",
    "y_hat_test = svm_opt.predict(X_test_sc)\n",
    "\n",
    "print(\"Train Accuracy:  \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test Accuracy:  \", accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:   0.8430962343096234\n",
      "Test Accuracy:   0.825\n"
     ]
    }
   ],
   "source": [
    "svm_opt = SVC(kernel = 'poly',\n",
    "              C = .0001, \n",
    "              gamma = 1,\n",
    "              probability=True)\n",
    "\n",
    "svm_opt.fit(X_train_sc, y_train)\n",
    "\n",
    "y_hat_train = svm_opt.predict(X_train_sc)\n",
    "y_hat_test = svm_opt.predict(X_test_sc)\n",
    "\n",
    "print(\"Train Accuracy:  \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test Accuracy:  \", accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Results for 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import 2018 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>office</th>\n",
       "      <th>loc_date</th>\n",
       "      <th>state</th>\n",
       "      <th>abbrev</th>\n",
       "      <th>year</th>\n",
       "      <th>winner</th>\n",
       "      <th>rival</th>\n",
       "      <th>pred_GOP</th>\n",
       "      <th>pred_DEM</th>\n",
       "      <th>unopposed</th>\n",
       "      <th>inc_GOP_running</th>\n",
       "      <th>inc_DEM_running</th>\n",
       "      <th>prez_GOP</th>\n",
       "      <th>approval_effects_GOP</th>\n",
       "      <th>approval_effects_DEM</th>\n",
       "      <th>nat_UR_effects_GOP</th>\n",
       "      <th>nat_UR_effects_DEM</th>\n",
       "      <th>state_UR_effects_GOP</th>\n",
       "      <th>state_UR_effects_DEM</th>\n",
       "      <th>percent_female</th>\n",
       "      <th>percent_age_18to29</th>\n",
       "      <th>percent_age_30to59</th>\n",
       "      <th>percent_age_60over</th>\n",
       "      <th>percent_race_white</th>\n",
       "      <th>percent_race_black</th>\n",
       "      <th>percent_race_asian</th>\n",
       "      <th>percent_race_hispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018_AZ_sen</td>\n",
       "      <td>AZ_sen</td>\n",
       "      <td>AZ_2018</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2018</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504449</td>\n",
       "      <td>0.165003</td>\n",
       "      <td>0.540617</td>\n",
       "      <td>0.205617</td>\n",
       "      <td>0.395501</td>\n",
       "      <td>0.045820</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.320867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018_CA_sen</td>\n",
       "      <td>CA_sen</td>\n",
       "      <td>CA_2018</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>2018</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503697</td>\n",
       "      <td>0.182023</td>\n",
       "      <td>0.590001</td>\n",
       "      <td>0.178872</td>\n",
       "      <td>0.150891</td>\n",
       "      <td>0.058239</td>\n",
       "      <td>0.319912</td>\n",
       "      <td>0.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018_CT_sen</td>\n",
       "      <td>CT_sen</td>\n",
       "      <td>CT_2018</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>CT</td>\n",
       "      <td>2018</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.511489</td>\n",
       "      <td>0.160426</td>\n",
       "      <td>0.572296</td>\n",
       "      <td>0.214690</td>\n",
       "      <td>0.582367</td>\n",
       "      <td>0.108996</td>\n",
       "      <td>0.113004</td>\n",
       "      <td>0.163416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018_DE_sen</td>\n",
       "      <td>DE_sen</td>\n",
       "      <td>DE_2018</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>DE</td>\n",
       "      <td>2018</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.516418</td>\n",
       "      <td>0.167856</td>\n",
       "      <td>0.563881</td>\n",
       "      <td>0.223531</td>\n",
       "      <td>0.549541</td>\n",
       "      <td>0.227139</td>\n",
       "      <td>0.081994</td>\n",
       "      <td>0.103068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018_FL_sen</td>\n",
       "      <td>FL_sen</td>\n",
       "      <td>FL_2018</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FL</td>\n",
       "      <td>2018</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.510712</td>\n",
       "      <td>0.161149</td>\n",
       "      <td>0.548872</td>\n",
       "      <td>0.241003</td>\n",
       "      <td>0.473384</td>\n",
       "      <td>0.167709</td>\n",
       "      <td>0.069587</td>\n",
       "      <td>0.259145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       race_id  office loc_date        state abbrev  year winner rival  \\\n",
       "0  2018_AZ_sen  AZ_sen  AZ_2018      Arizona     AZ  2018    TBD   TBD   \n",
       "1  2018_CA_sen  CA_sen  CA_2018   California     CA  2018    TBD   TBD   \n",
       "2  2018_CT_sen  CT_sen  CT_2018  Connecticut     CT  2018    TBD   TBD   \n",
       "3  2018_DE_sen  DE_sen  DE_2018     Delaware     DE  2018    TBD   TBD   \n",
       "4  2018_FL_sen  FL_sen  FL_2018      Florida     FL  2018    TBD   TBD   \n",
       "\n",
       "   pred_GOP  pred_DEM  unopposed  inc_GOP_running  inc_DEM_running  prez_GOP  \\\n",
       "0         1         0          0                0                0       1.0   \n",
       "1         0         1          0                0                1       1.0   \n",
       "2         0         1          0                0                1       1.0   \n",
       "3         0         1          0                0                1       1.0   \n",
       "4         0         1          0                0                1       1.0   \n",
       "\n",
       "   approval_effects_GOP  approval_effects_DEM  nat_UR_effects_GOP  \\\n",
       "0                  -8.5                     0                 3.7   \n",
       "1                  -8.5                     0                 3.7   \n",
       "2                  -8.5                     0                 3.7   \n",
       "3                  -8.5                     0                 3.7   \n",
       "4                  -8.5                     0                 3.7   \n",
       "\n",
       "   nat_UR_effects_DEM  state_UR_effects_GOP  state_UR_effects_DEM  \\\n",
       "0                   0                   4.7                     0   \n",
       "1                   0                   4.1                     0   \n",
       "2                   0                   4.2                     0   \n",
       "3                   0                   4.0                     0   \n",
       "4                   0                   3.5                     0   \n",
       "\n",
       "   percent_female  percent_age_18to29  percent_age_30to59  percent_age_60over  \\\n",
       "0        0.504449            0.165003            0.540617            0.205617   \n",
       "1        0.503697            0.182023            0.590001            0.178872   \n",
       "2        0.511489            0.160426            0.572296            0.214690   \n",
       "3        0.516418            0.167856            0.563881            0.223531   \n",
       "4        0.510712            0.161149            0.548872            0.241003   \n",
       "\n",
       "   percent_race_white  percent_race_black  percent_race_asian  \\\n",
       "0            0.395501            0.045820            0.156100   \n",
       "1            0.150891            0.058239            0.319912   \n",
       "2            0.582367            0.108996            0.113004   \n",
       "3            0.549541            0.227139            0.081994   \n",
       "4            0.473384            0.167709            0.069587   \n",
       "\n",
       "   percent_race_hispanic  \n",
       "0               0.320867  \n",
       "1               0.411700  \n",
       "2               0.163416  \n",
       "3               0.103068  \n",
       "4               0.259145  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_year = pd.read_csv('/Users/Alexz/CodeMaster/capstone/capstone_repo/data/2018_final.csv')\n",
    "# drop non-analysis vars\n",
    "this_year.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "\n",
    "\n",
    "# Option 1: drop amount vars from X\n",
    "this_year.drop(amnt_columns, axis=1, inplace=True)\n",
    "# drop out group from binary/collinear groups\n",
    "this_year.drop(['percent_male', 'percent_under18', 'percent_race_natamer'], inplace=True, axis=1)\n",
    "\n",
    "id_cols = ['office', 'loc_date', 'race_id', 'state', 'abbrev', 'year', 'winner', 'rival']\n",
    "\n",
    "\n",
    "print(this_year.shape)\n",
    "this_year.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Scale Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(598, 20)\n",
      "(35, 20)\n"
     ]
    }
   ],
   "source": [
    "X_final = this_year.drop(id_cols, axis = 1)\n",
    "print(X.shape)\n",
    "print(X_final.shape)\n",
    "X_final_sc = ss.transform(X_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Voting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:   0.8493723849372385\n",
      "Test Accuracy:   0.8416666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexz\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Alexz\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "voter = VotingClassifier([('knn', knn_opt),\n",
    "                          ('dtree', dt_opt),\n",
    "                          ('bagging', bag_opt),\n",
    "                          ('rf', rf_opt),\n",
    "                          ('svm', svm_opt),\n",
    "                          ('logreg', lr_opt), \n",
    "                          ('boost', boost_opt)],\n",
    "                          voting='soft')\n",
    "\n",
    "# Test Model Against original train and test data\n",
    "voter.fit(X_train_sc, y_train)\n",
    "\n",
    "y_hat_train = voter.predict(X_train_sc)\n",
    "y_hat_test = voter.predict(X_test_sc)\n",
    "\n",
    "print(\"Train Accuracy:  \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test Accuracy:  \", accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use to predict 2018 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexz\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#train against all data before running on 2018\n",
    "voter.fit(X, y)\n",
    "\n",
    "results = voter.predict(X_final)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_year['predictions'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 29)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_year.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018_AZ_sen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018_CA_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018_CT_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018_DE_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018_FL_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018_HI_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018_IN_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018_ME_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018_MD_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018_MA_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018_MI_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018_MS_sen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018_MS_sen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018_MN_sen1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018_MN_sen2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018_MO_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018_MT_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018_NE_sen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018_NV_sen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018_NJ_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018_NM_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018_NY_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018_ND_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018_OH_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018_PA_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018_RI_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018_TN_sen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018_TX_sen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018_UT_sen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018_VT_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018_VA_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018_WA_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018_WV_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018_WI_sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2018_WY_sen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         race_id  predictions\n",
       "0    2018_AZ_sen            1\n",
       "1    2018_CA_sen            0\n",
       "2    2018_CT_sen            0\n",
       "3    2018_DE_sen            0\n",
       "4    2018_FL_sen            0\n",
       "5    2018_HI_sen            0\n",
       "6    2018_IN_sen            0\n",
       "7    2018_ME_sen            0\n",
       "8    2018_MD_sen            0\n",
       "9    2018_MA_sen            0\n",
       "10   2018_MI_sen            0\n",
       "11   2018_MS_sen            1\n",
       "12   2018_MS_sen            1\n",
       "13  2018_MN_sen1            0\n",
       "14  2018_MN_sen2            0\n",
       "15   2018_MO_sen            0\n",
       "16   2018_MT_sen            0\n",
       "17   2018_NE_sen            1\n",
       "18   2018_NV_sen            1\n",
       "19   2018_NJ_sen            0\n",
       "20   2018_NM_sen            0\n",
       "21   2018_NY_sen            0\n",
       "22   2018_ND_sen            0\n",
       "23   2018_OH_sen            0\n",
       "24   2018_PA_sen            0\n",
       "25   2018_RI_sen            0\n",
       "26   2018_TN_sen            1\n",
       "27   2018_TX_sen            1\n",
       "28   2018_UT_sen            1\n",
       "29   2018_VT_sen            0\n",
       "30   2018_VA_sen            0\n",
       "31   2018_WA_sen            0\n",
       "32   2018_WV_sen            0\n",
       "33   2018_WI_sen            0\n",
       "34   2018_WY_sen            1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_year.loc[:, ['race_id', 'predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
